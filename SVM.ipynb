{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUMaYewRSZnR3QOVn+L57e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khyatiraka/machineLearningKhyati/blob/main/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T8DvlGob_lr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "import re\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read csv\n",
        "path = \"/content/Train.csv\"\n",
        "df = pd.read_csv(path, quoting=3, on_bad_lines='skip') # Added quoting and error_bad_lines parameters\n",
        "#nltk.download('stopwords')\n",
        "#df.info()\n",
        "#df.isnull().sum()\n",
        "df = df.dropna()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88nvqXxcvcM",
        "outputId": "ad4b8feb-40e5-4c2f-a0ae-ccb2eef4a00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "MultiIndex: 2453 entries, ('\"I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"\"Thunderbirds\"\" before school', ' during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair') to ('\"I really love anything done by Savage Steve Holland', ' the writer/director of this great movie. Also see \"\"Better Off Dead\"\" and \"\"How I Got Into College.\"\" Wonderful! Anyway this movie is really humorous and delivers some unexpected things. Where else but in this movie can you see Demi Moore as a talented singer and Bobcat Golthwait as a twin? I recommend this to anybody looking for some old fashioned slapstick comedy (George with the turtle raft)')\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   text    2453 non-null   object \n",
            " 1   label   2453 non-null   float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 386.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#need to convert the words to numbers\n",
        "\n",
        "df = df[df['text'].apply(lambda x: isinstance(x, str))]\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)  # Remove @mentions and hashtags\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and special characters\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Apply text preprocessing\n",
        "df['clean_tweet'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "#stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Tokenization & Stopword Removal\n",
        "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_tweet'], df['label'], test_size=0.2, random_state=42)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cbPL7Wf5fGWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an SVM classifier\n",
        "# svm_model = SVC(kernel='linear', C=1.0)  # Use linear kernel for text classification\n",
        "# svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "svm = SVC(kernel='rbf', C=10, gamma=0.1)\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "# Make predictions\n",
        "y_pred = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeqKo5wUlHiI",
        "outputId": "8018d212-8bb7-4f12-afb2-08b0ec61fe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7393075356415478\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.72      0.74      0.73       233\n",
            "         1.0       0.76      0.74      0.75       258\n",
            "\n",
            "    accuracy                           0.74       491\n",
            "   macro avg       0.74      0.74      0.74       491\n",
            "weighted avg       0.74      0.74      0.74       491\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-vPoa-7Rk4SF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}